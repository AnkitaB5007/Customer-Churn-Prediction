{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "040741ec",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Hyperparameter Tuning (Full Performance Mode)\n",
    "\n",
    "*Note: This section is optional and will significantly increase runtime (20-60 minutes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full hyperparameter tuning (uncomment to enable)\n",
    "# WARNING: This will take 20-60 minutes depending on your hardware\n",
    "\n",
    "ENABLE_HYPERPARAMETER_TUNING = False  # Set to True for full tuning\n",
    "\n",
    "if ENABLE_HYPERPARAMETER_TUNING and best_model_name:\n",
    "    print(f\"üîß Full hyperparameter tuning for {best_model_name}...\")\n",
    "    \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # Full parameter grids\n",
    "    param_grids = {\n",
    "        'Logistic Regression': {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'max_iter': [1000, 2000]\n",
    "        },\n",
    "        'Random Forest': {\n",
    "            'n_estimators': [50, 100, 200, 300],\n",
    "            'max_depth': [10, 20, 30, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'bootstrap': [True, False]\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'n_estimators': [50, 100, 200, 300],\n",
    "            'max_depth': [3, 4, 5, 6, 8],\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if best_model_name in param_grids:\n",
    "        base_model = trained_models[best_model_name]\n",
    "        param_grid = param_grids[best_model_name]\n",
    "        \n",
    "        print(f\"Grid search with {len(param_grid)} parameters...\")\n",
    "        print(f\"Estimated combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            base_model, \n",
    "            param_grid, \n",
    "            cv=LAPTOP_CONFIG['grid_cv'],\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=LAPTOP_CONFIG['n_jobs'],\n",
    "            verbose=2,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        \n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        tuning_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\\\n‚úÖ Hyperparameter tuning completed in {tuning_time/60:.1f} minutes\")\n",
    "        print(f\"‚úÖ Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"‚úÖ Best CV score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"‚úÖ Improvement: {grid_search.best_score_ - model_results[best_model_name]['cv_mean']:.4f}\")\n",
    "        \n",
    "        # Update best model\n",
    "        best_tuned_model = grid_search.best_estimator_\n",
    "        trained_models[f\"{best_model_name} (Tuned)\"] = best_tuned_model\n",
    "        \n",
    "    else:\n",
    "        print(f\"No parameter grid defined for {best_model_name}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Hyperparameter tuning skipped (set ENABLE_HYPERPARAMETER_TUNING = True to enable)\")\n",
    "    print(\"üí° This saves 20-60 minutes of computation time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85f8dc",
   "metadata": {},
   "source": [
    "# üíª Customer Churn Prediction - Reduced Edition (8GB RAM Optimized)\n",
    "\n",
    "This notebook is specifically optimized for my laptop with 8GB RAM for faster execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992320e",
   "metadata": {},
   "source": [
    "## üíª Laptop Configuration & Memory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdab172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laptop-optimized settings\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "def check_memory():\n",
    "    \"\"\"Monitor memory usage\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"Memory: {mem.percent:.1f}% used ({mem.used/1024**3:.1f}GB/{mem.total/1024**3:.1f}GB)\")\n",
    "    \n",
    "def cleanup_memory():\n",
    "    \"\"\"Force garbage collection\"\"\"\n",
    "    gc.collect()\n",
    "    print(\" Memory cleaned up\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb3579-30e0-4559-ac14-555737d23d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIM_CONFIG = {\n",
    "    'cv_folds': 3,           # Reduced CV folds\n",
    "    'n_jobs': 2,             # Limited parallel processing  \n",
    "    'rf_estimators': 50,     # Fewer trees\n",
    "    'max_iter': 500,         # Fewer iterations\n",
    "    'grid_cv': 2,            # Smaller grid search\n",
    "    'verbose': True          # Progress tracking\n",
    "}\n",
    "\n",
    "print(\" Laptop mode configuration loaded!\")\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47066464",
   "metadata": {},
   "source": [
    "##  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"XGBoost available (will use minimal settings)\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available (skipping)\")\n",
    "\n",
    "# Custom preprocessing\n",
    "from src.preprocessing import ChurnDataPreprocessor\n",
    "\n",
    "# Simple plotting style\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"Lightweight imports complete!\")\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ab9c7",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e300793",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load data\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "print(\"\\n Initializing preprocessor...\")\n",
    "preprocessor = ChurnDataPreprocessor()\n",
    "\n",
    "# Quick preprocessing\n",
    "print(\"Running FAST preprocessing pipeline...\")\n",
    "X_train, X_test, y_train, y_test = preprocessor.full_preprocessing_pipeline(\n",
    "    df, target_col='Churn', test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "preprocessing_time = time.time() - start_time\n",
    "print(f\"\\n Preprocessing completed in {preprocessing_time:.1f} seconds!\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")\n",
    "\n",
    "check_memory()\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be8ac3",
   "metadata": {},
   "source": [
    "## üöÄ Laptop-Optimized Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize laptop-friendly models\n",
    "print(\"üîß Setting up laptop-optimized models...\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=OPTIM_CONFIG['max_iter'],\n",
    "        solver='liblinear',  # Faster solver\n",
    "        n_jobs=1  # Single core for stability\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=OPTIM_CONFIG['rf_estimators'],  # Reduced trees\n",
    "        max_depth=15,  # Limit depth\n",
    "        n_jobs=OPTIM_CONFIG['n_jobs'],  # Limited parallel\n",
    "        min_samples_split=5,  # Faster training\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "}\n",
    "\n",
    "# Optional XGBoost with minimal settings\n",
    "if XGBOOST_AVAILABLE:\n",
    "    models['XGBoost (Lite)'] = XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=30,  # Very few estimators\n",
    "        max_depth=4,      # Shallow trees\n",
    "        learning_rate=0.1,\n",
    "        eval_metric='logloss',\n",
    "        enable_categorical=False,\n",
    "        use_label_encoder=False,\n",
    "        verbosity=0,\n",
    "        n_jobs=1  # Single thread\n",
    "    )\n",
    "    print(\"‚ûï XGBoost Lite added (minimal resource usage)\")\n",
    "\n",
    "print(f\"üéØ {len(models)} models ready for training\")\n",
    "print(f\"Models: {list(models.keys())}\")\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ccc5c",
   "metadata": {},
   "source": [
    "## ‚ö° Fast Model Training (3-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training with progress tracking\n",
    "model_results = {}\n",
    "trained_models = {}\n",
    "training_times = {}\n",
    "\n",
    "# Fast cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=OPTIM_CONFIG['cv_folds'], shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"‚ö° FAST training mode: {OPTIM_CONFIG['cv_folds']}-fold CV\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "overall_start = time.time()\n",
    "\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    print(f\"\\n[{i}/{len(models)}] Training {name}...\")\n",
    "    model_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[name] = model\n",
    "        \n",
    "        # Fast cross-validation\n",
    "        if 'XGBoost' in name:\n",
    "            # Manual CV for XGBoost compatibility\n",
    "            cv_scores = []\n",
    "            for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "                X_fold_train = X_train.iloc[train_idx]\n",
    "                X_fold_val = X_train.iloc[val_idx]\n",
    "                y_fold_train = y_train.iloc[train_idx]\n",
    "                y_fold_val = y_train.iloc[val_idx]\n",
    "                \n",
    "                fold_model = XGBClassifier(\n",
    "                    random_state=42, n_estimators=30, max_depth=4,\n",
    "                    learning_rate=0.1, eval_metric='logloss',\n",
    "                    enable_categorical=False, use_label_encoder=False,\n",
    "                    verbosity=0, n_jobs=1\n",
    "                )\n",
    "                fold_model.fit(X_fold_train, y_fold_train)\n",
    "                y_pred_proba = fold_model.predict_proba(X_fold_val)[:, 1]\n",
    "                score = roc_auc_score(y_fold_val, y_pred_proba)\n",
    "                cv_scores.append(score)\n",
    "            cv_scores = np.array(cv_scores)\n",
    "        else:\n",
    "            # Standard CV for other models\n",
    "            cv_scores = cross_val_score(\n",
    "                model, X_train, y_train, \n",
    "                cv=cv, scoring='roc_auc', \n",
    "                n_jobs=1  # Single job for laptop\n",
    "            )\n",
    "        \n",
    "        # Store results\n",
    "        model_results[name] = {\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'cv_scores': cv_scores\n",
    "        }\n",
    "        \n",
    "        model_time = time.time() - model_start\n",
    "        training_times[name] = model_time\n",
    "        \n",
    "        print(f\" ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        print(f\" Time: {model_time:.1f}s\")\n",
    "        \n",
    "        # Memory check after each model\n",
    "        if OPTIM_CONFIG['verbose']:\n",
    "            check_memory()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error training {name}: {str(e)[:100]}...\")\n",
    "        print(f\" Skipping and continuing...\")\n",
    "        continue\n",
    "\n",
    "total_time = time.time() - overall_start\n",
    "print(f\"\\n Training completed in {total_time:.1f} seconds!\")\n",
    "print(f\" Successfully trained {len(trained_models)} models\")\n",
    "\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eea569",
   "metadata": {},
   "source": [
    "## üìä Quick Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc83d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast performance overview\n",
    "print(\" LAPTOP PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if model_results:\n",
    "    # Create simple performance table\n",
    "    results_data = []\n",
    "    for name, results in model_results.items():\n",
    "        results_data.append({\n",
    "            'Model': name,\n",
    "            'ROC-AUC': f\"{results['cv_mean']:.4f}\",\n",
    "            'Std': f\"{results['cv_std']:.4f}\",\n",
    "            'Time (s)': f\"{training_times[name]:.1f}\"\n",
    "        })\n",
    "    \n",
    "    performance_df = pd.DataFrame(results_data)\n",
    "    performance_df = performance_df.sort_values('ROC-AUC', ascending=False)\n",
    "    \n",
    "    print(performance_df.to_string(index=False))\n",
    "    \n",
    "    # Best model\n",
    "    best_model_name = performance_df.iloc[0]['Model']\n",
    "    best_score = performance_df.iloc[0]['ROC-AUC']\n",
    "    print(f\"\\n Best model: {best_model_name} (ROC-AUC: {best_score})\")\n",
    "    \n",
    "else:\n",
    "    print(\"No models trained successfully\")\n",
    "    best_model_name = None\n",
    "\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38486b",
   "metadata": {},
   "source": [
    "## üéØ Test Set Evaluation (Best Model Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test evaluation for best model only (saves time/memory)\n",
    "if best_model_name and best_model_name in trained_models:\n",
    "    print(f\" Evaluating {best_model_name} on test set...\")\n",
    "    \n",
    "    best_model = trained_models[best_model_name]\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n TEST SET RESULTS:\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC:  {test_roc_auc:.4f}\")\n",
    "    \n",
    "    # Simple confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n Confusion Matrix:\")\n",
    "    print(f\"True Neg: {cm[0,0]:4d} | False Pos: {cm[0,1]:4d}\")\n",
    "    print(f\"False Neg: {cm[1,0]:4d} | True Pos:  {cm[1,1]:4d}\")\n",
    "    \n",
    "else:\n",
    "    print(\" No model available for evaluation\")\n",
    "    \n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce631c",
   "metadata": {},
   "source": [
    "## üíæ Quick Model Save (Essential Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00233897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the best model (saves disk space)\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "if best_model_name and best_model_name in trained_models:\n",
    "    print(\" Saving best model and preprocessor...\")\n",
    "    \n",
    "    # Create models directory\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # Save best model\n",
    "    model_filename = f'models/laptop_best_churn_model.pkl'\n",
    "    joblib.dump(trained_models[best_model_name], model_filename)\n",
    "    print(f\"Model saved: {model_filename}\")\n",
    "    \n",
    "    # Save preprocessor\n",
    "    preprocessor_filename = 'models/laptop_churn_preprocessor.pkl'\n",
    "    preprocessor.save_preprocessor(preprocessor_filename)\n",
    "    \n",
    "    # Save model info\n",
    "    model_info = {\n",
    "        'model_name': best_model_name,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_roc_auc': test_roc_auc,\n",
    "        'training_time': training_times[best_model_name],\n",
    "        'config': OPTIM_CONFIG\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open('models/laptop_model_info.json', 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    \n",
    "    print(f\" Model info saved: models/laptop_model_info.json\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No model to save\")\n",
    "\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d481ca",
   "metadata": {},
   "source": [
    "## üéâ Laptop Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary optimized for laptop\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LAPTOP TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if best_model_name:\n",
    "    print(f\" Best Model: {best_model_name}\")\n",
    "    print(f\" Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\" Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "    print(f\" Training Time: {training_times[best_model_name]:.1f}s\")\n",
    "    print(f\" Model saved and ready for Streamlit app!\")\n",
    "else:\n",
    "    print(\" No models were successfully trained\")\n",
    "\n",
    "print(f\"\\n Optimised/reduced Configuration Used:\")\n",
    "for key, value in OPTIM_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n Total Runtime: {time.time() - overall_start:.1f} seconds\")\n",
    "print(f\" Optimized for 8GB RAM laptops ‚úÖ\")\n",
    "\n",
    "final_memory = psutil.virtual_memory()\n",
    "print(f\" Final Memory Usage: {final_memory.percent:.1f}%\")\n",
    "print(\"\\n Ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
